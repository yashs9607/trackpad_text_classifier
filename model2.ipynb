{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 04:03:36.445149: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-09 04:03:36.446277: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-09 04:03:36.474664: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-09 04:03:36.475190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-09 04:03:37.077769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, LSTM, Dropout, Convolution2D, MaxPool2D, Flatten, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from seqframe.seqframe import seq_frame\n",
    "from keras.regularizers import L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "no_sequences = 30\n",
    "no_frames = 1500\n",
    "words = ['hello', 'world', 'i_am', 'yash']\n",
    "PATH = '/home/yash/Desktop/Code/trackpad_text_detection/word_data/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate\n",
    "import cv2\n",
    "\n",
    "def random_resize_crop(image, output_shape):\n",
    "    if image is None:\n",
    "        raise ValueError(\"Invalid input image.\")\n",
    "\n",
    "    # Randomly select a scaling factor between 0.8 and 1.2\n",
    "    scale_factor = np.random.uniform(0.7, 1.4)\n",
    "\n",
    "    # Calculate the maximum possible size for the crop\n",
    "    max_crop_height = int(output_shape[0] / scale_factor)\n",
    "    max_crop_width = int(output_shape[1] / scale_factor)\n",
    "\n",
    "    # Calculate the upper bounds for random crop position\n",
    "    max_start_h = max(image.shape[0] - max_crop_height, 0)\n",
    "    max_start_w = max(image.shape[1] - max_crop_width, 0)\n",
    "\n",
    "    # Randomly select the crop position\n",
    "    start_h = np.random.randint(0, max_start_h + 1)\n",
    "    start_w = np.random.randint(0, max_start_w + 1)\n",
    "\n",
    "    # Calculate the end position of the crop\n",
    "    end_h = start_h + max_crop_height\n",
    "    end_w = start_w + max_crop_width\n",
    "\n",
    "    # Perform the crop\n",
    "    cropped_image = image[start_h:end_h, start_w:end_w]\n",
    "\n",
    "    # Resize the cropped image to the desired output shape using OpenCV\n",
    "    resized_image = cv2.resize(cropped_image, output_shape[::-1])\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "\n",
    "def random_rotate(image):\n",
    "    # Randomly select an angle between -15 and 15 degrees\n",
    "    angle = np.random.uniform(-15, 15)\n",
    "\n",
    "    # Get the image center coordinates\n",
    "    image_height, image_width = image.shape[:2]\n",
    "    center_x = image_width // 2\n",
    "    center_y = image_height // 2\n",
    "\n",
    "    # Define the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((center_x, center_y), angle, 1.0)\n",
    "\n",
    "    # Apply the rotation to the image using OpenCV\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (image_width, image_height), borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "def augment(img):\n",
    "    temp = random_resize_crop(img, img.shape)\n",
    "    temp = random_rotate(temp)\n",
    "    return temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# a = np.load('word_data/hello_/0/1099.npy')\n",
    "# b = augment(a)\n",
    "# plt.imshow(b.T)\n",
    "\n",
    "# assert b.shape==a.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n  = (1919, 1079)\n",
    "scale = 10\n",
    "sample_rate = 5\n",
    "import os\n",
    "samples = []\n",
    "for i, word in enumerate(words):\n",
    "    for sequence in range(no_sequences):\n",
    "        frames = []\n",
    "        x = np.load(os.path.join(PATH, word, f'{sequence}.npy'))\n",
    "        temp = np.zeros((m//scale, n//scale))\n",
    "        for j, coord in enumerate(x):\n",
    "            temp[int(coord[0]//scale)][int(coord[1]//scale)] = 1\n",
    "            temp = temp.astype('uint8')\n",
    "            if j%sample_rate == 0:\n",
    "                aug_temp = augment(temp)\n",
    "                frames.append(aug_temp)\n",
    "        samples.append(np.array(frames))\n",
    "x = np.array(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape\n",
    "x = x.reshape((-1, 191, 107, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000, 191, 107, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([i for i, _ in enumerate(words) for j in range(no_sequences*int(np.ceil(no_frames/sample_rate)))])\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "# 13200/110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.1, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, kernel_size=(5,5), strides=3))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Convolution2D(64, kernel_size=(3,3), strides=2))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Convolution2D(128, kernel_size=(3,3), strides=1))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# # model.add(Reshape((-1, 256,1)))\n",
    "\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=L2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=L2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=L2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (32400, 63, 35, 32)       832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (32400, 31, 17, 32)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (32400, 15, 8, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (32400, 7, 4, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (32400, 5, 2, 128)        73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (32400, 2, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (32400, 256)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (32400, 256)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (32400, 128)              32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (32400, 128)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32400, 64)               8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (32400, 64)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (32400, 32)               2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (32400, 32)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (32400, 4)                132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136548 (533.39 KB)\n",
      "Trainable params: 136548 (533.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# _, _, m, n = x.shape\n",
    "model.build(X_train.shape)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from tqdm import tqdm\n",
    "# state_accuracy=[]\n",
    "# for i in tqdm(range(3)):\n",
    "#     oof_scores = []\n",
    "#     skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=i)\n",
    "#     for train_index, valid_index in skf.split(X_train, np.argmax(y_train,axis=1)):\n",
    "#         xtrain, ytrain = X_train[train_index], y_train[train_index]\n",
    "#         xvalid, yvalid = X_train[valid_index], y_train[valid_index]\n",
    "        \n",
    "#         model.fit(xtrain, ytrain, epochs=5)\n",
    "#         preds=model.predict(xvalid)\n",
    "#         ytrue = np.argmax(yvalid, axis=1)\n",
    "#         yhat = np.argmax(preds, axis=1)\n",
    "#         oof_scores.append(accuracy_score(ytrue, yhat))\n",
    "#     state_accuracy.append(np.array(oof_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.mean(state_accuracy, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(X_train,y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_hat = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model2_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.mean(preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 10s 9ms/step - loss: 1.1092 - categorical_accuracy: 0.5861\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 10s 9ms/step - loss: 0.6053 - categorical_accuracy: 0.7802\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 10s 9ms/step - loss: 0.5026 - categorical_accuracy: 0.8177\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 10s 9ms/step - loss: 0.4563 - categorical_accuracy: 0.8357\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 10s 9ms/step - loss: 0.4198 - categorical_accuracy: 0.8505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/Desktop/Code/trackpad_text_detection/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x,y, epochs=5)\n",
    "# model.save('model2_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackpad_text_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
